const {onObjectFinalized} = require("firebase-functions/v2/storage");
const {defineSecret} = require("firebase-functions/params");
const {initializeApp} = require("firebase-admin/app");
const {getFirestore, FieldValue} = require("firebase-admin/firestore");
const vision = require("@google-cloud/vision");
const path = require("path");
const os = require("os");
const fs = require("fs");
const {OpenAI} = require("openai"); // ‚úÖ OpenAI SDK v4+

// üîê Access OpenAI API key securely
const OPENAI_API_KEY = defineSecret("OPENAI_API_KEY");

// üèÅ Init Firebase
initializeApp();
const db = getFirestore();
const visionClient = new vision.ImageAnnotatorClient();

// üëÅ‚Äçüó® Image Upload Trigger with OCR + OpenAI
exports.ocrOnImageUpload = onObjectFinalized(
    {
      secrets: [OPENAI_API_KEY],
    },
    async (event) => {
      const filePath = event.data.name;

      if (!filePath) {
        console.log("‚ùå No filePath found in event:", event);
        return;
      }

      const bucket = require("firebase-admin").storage().bucket(event.data.bucket);// eslint-disable-line max-len
      const file = bucket.file(filePath);

      const [metadata] = await file.getMetadata();
      const contentType = metadata.contentType || "";

      if (!contentType.startsWith("image/")) {
        console.log("‚õîÔ∏è Skipped non-image file:", filePath);
        return;
      }

      const fileName = path.basename(filePath);
      const tempFilePath = path.join(os.tmpdir(), fileName);

      // ‚¨áÔ∏è Download image locally
      await file.download({destination: tempFilePath});
      console.log(`‚úÖ Image downloaded locally to ${tempFilePath}`);

      // üîç OCR using Google Vision
      const [result] = await visionClient.textDetection(tempFilePath);
      const detections = result.textAnnotations;

      if (!detections || detections.length === 0) {
        console.log("‚ö†Ô∏è No text detected.");
        return;
      }

      const extractedText = detections[0].description;
      console.log("üß† Extracted text:", extractedText);

      try {
      // ü§ñ Send to OpenAI for parsing
        const openai = new OpenAI({
          apiKey: OPENAI_API_KEY.value(),
        });

        const aiResponse = await openai.chat.completions.create({
          model: "gpt-4",
          messages: [
            {
              role: "system",
              content:
              "You are a travel assistant that extracts structured booking info from OCR text. Return JSON with keys: date, time, from, to, price, name(s), transport_mode.", // eslint-disable-line max-len
            },
            {
              role: "user",
              content: extractedText,
            },
          ],
        });

        console.log("üì• Full AI response:", JSON.stringify(aiResponse, null, 2));

        const parsedData = aiResponse.choices[0].message.content;
        console.log("üì¶ AI-parsed data:", parsedData);

        // üíæ Save to Firestore
        await db.collection("ocrResults").add({
          file: fileName,
          originalText: extractedText,
          parsed: parsedData,
          timestamp: FieldValue.serverTimestamp(),
        });
      } catch (err) {
        console.error("‚ùå OpenAI call failed:", err.message);
      } finally {
      // üßπ Cleanup
        fs.unlinkSync(tempFilePath);
      }
    },
);
